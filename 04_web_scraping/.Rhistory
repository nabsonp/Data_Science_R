x = c(2)/
demo()
x = c(4)
x = c(1,2,3)
y = c(3,4,2,2)
tabela_artigo_manipuladores <- read.csv("~/Documentos/UFAM/4º período/ICD/tabela_artigo_manipuladores.csv")
View(tabela_artigo_manipuladores)
tabela_artigo_manipuladores <- read.delim("~/Documentos/UFAM/4º período/ICD/tabela_artigo_manipuladores.csv", comment.char="#")
View(tabela_artigo_manipuladores)
View(tabela_artigo_manipuladores)
df <- tabela_artigo_manipuladores
cor(df)
x = df[,4:6]/apply(df[,4:6],1,SUM) # matriz[<linhas>,<colunas>]
x = df[,4:6]/apply(df[,4:6],1,sum) # matriz[<linhas>,<colunas>]
df2 = cbind(df[,2:3],x,df[,7]) # concatena matriz em colunas
# i:j = [i, ..., j]
# apply(<matriz>,<linha=1/coluna=2>,<funcao>)
df2 = cbind(df[,2:3],x,PACHS = df[,7]) # concatena matriz em colunas
x
# i:j = [i, ..., j]
# apply(<matriz>,<linha=1/coluna=2>,<funcao>)
df2 = cbind(PCap = df[3]/df[,2],x,PACHS = df[,7]) # concatena matriz em colunas
df
# i:j = [i, ..., j]
# apply(<matriz>,<linha=1/coluna=2>,<funcao>)
df2 = cbind(PCap = df[3]/df[,2],x,PACHS = df[,6]) # concatena matriz em colunas
df2
cor(df2)
plot(df2[,1],df2[,4],pch=19,cex=2)
plot(df2[,3],df2[,1],pch=19,cex=2) # plota o gráfico de dispersão
plot(df2[,3],df2[,1],pch=1,cex=2) # plota o gráfico de dispersão
plot(df2[,3],df2[,1],pch=19,cex=2) # plota o gráfico de dispersão
plot(df2[,3],df2[,1],pch=19,cex=1) # plota o gráfico de dispersão
# install.packages("rvest") # usado para fazer web scraping
library(rvest)
library(stringr)
df = data.frame(Product = NA, Price = NA)
#
URL = "https://www.olx.com.br/brasil?o=PAGINA&q=im%C3%B3veis%20a%20venda%20em%20manaus&sf=1"
k = 1
while (k < 11) {
url = sub(x=URL,pattern = 'PAGINA',replacement = k)
page = read_html(url) # Lê a página na url
# Get product names ----
pagenode = html_nodes(x = page, xpath = "//div//li//a//div//div//h2") # Separa a página de acordo com as tags HTML
texts   = html_text(pagenode) # Pega o nome dos produtos
prod = str_replace_all(texts,'\t','')
prod = str_replace_all(prod,'\n','')
# Get product price ----
pagenode = html_nodes(x = page, xpath = "//div//li//a//p")
texts    = html_text(pagenode)
idtext   = grep(":| R\\$", texts) # Pego somente os preços e horários, para analisar quais que não têm preço
texts    = texts[idtext]
i = 1
j = 1
l = length(texts)
price = c() # Usado para separar preços de horários de postagem
while (i < l) {
if (!grepl("R",texts[i])){
price[j] <- NA # Alguns produtos não têm preço na página
i = i + 1
} else {
price[j] <- texts[i]
# Trata o fato de que podem ter dois preços no produto, o antigo e o atual
if (grepl("R",texts[i+1])) {
i = i + 3
} else {
i = i + 2
}
}
j = j + 1
}
price = str_replace_all(price,' ','')
# ----
df = rbind.data.frame(df,cbind.data.frame(Product = prod,Price = price))
cat("Page: ", k ,"\t Products: ",nrow(df)-1,"\n")
k = k + 1
Sys.sleep(runif(1,0,5))
}
df = df[-1,]
View(df)
setwd("~/Documentos/UFAM/4º período/ICD/Aula 06")
write.csv(df, "web_scrapping_olx.csv", row.names = TRUE)
